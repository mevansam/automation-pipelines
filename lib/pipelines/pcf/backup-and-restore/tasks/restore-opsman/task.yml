---
platform: linux

image_resource:
  type: docker-image
  source: 
    repository: appbricks/tools

inputs:
- name: automation
- name: restore-timestamp

run:
  path: automation/lib/pipelines/pcf/backup-and-restore/tasks/restore-opsman/task.sh

outputs:
- name: job-session

params:
  TRACE: Y

  ## SSH private key used to access cloud resources
  SSH_KEY:
  
  ## Ops Manager credentials
  OPSMAN_HOST:
  OPSMAN_USERNAME:
  OPSMAN_PASSWORD:
  OPSMAN_SSH_USER:
  OPSMAN_SSH_PASSWD:
  OPSMAN_DECRYPTION_KEY:
  OPSMAN_CLIENT_ID:
  OPSMAN_CLIENT_SECRET:

  ## Backup storage backend type should be one of 'scp', 's3', 'swift'
  BACKUP_TYPE:
  BACKUP_TARGET:
  
  ## Params to upload backups to S3 Storage
  S3_ENDPOINT:
  S3_BUCKET_NAME:
  S3_ACCESS_KEY_ID:
  S3_SECRET_ACCESS_KEY:
  S3_REGION:

  ## Credentials for GCS access
  GCP_SERVICE_ACCOUNT_KEY:
  
  # Params to upload backups to OpenStack Swift Storage
  OS_AUTH_URL:
  OS_IDENTITY_API_VERSION:
  OS_PROJECT_DOMAIN_NAME:
  OS_PROJECT_NAME:
  OS_USER_DOMAIN_NAME:
  OS_USERNAME:
  OS_PASSWORD:

  ## Mount options to upload backups via a remote mount. This
  ## removes the need to have sufficient disk space on the 
  ## concourse workers as backups are downloaded directly
  ## to the mount path. Only one of S3FS/Cloudfuse/NFS
  ## maybe used. To configure the correct mount simply
  ## set the mount path.
  MOUNT_OPTIONS:

  ## S3FS mount path
  S3FS_MOUNT:
  S3FS_USE_PATH_REQUEST_STYLE:
  S3FS_DEBUG:

  ## GCS mount bucker and path
  GCS_BUCKET_NAME:
  GCS_MOUNT:
  GCSFUSE_OPTIONS:
  GCSFUSE_DEBUG:

  ## Cloudfuse mount path
  CLOUDFUSE_MOUNT:
  CLOUDFUSE_DEBUG:

  ## NFS mount path
  NFS_MOUNT:
